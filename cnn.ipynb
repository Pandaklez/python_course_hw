{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple CNN and RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "import nltk\n",
    "import gensim\n",
    "import spacy\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import torch as tt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchtext.data import Field, LabelField, BucketIterator, TabularDataset, Iterator\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"head\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "!head Tweets.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 TorchText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "\n",
    "spacy_en = spacy.load('en')\n",
    "\n",
    "def tokenizer(text): # create a tokenizer function\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text) if tok.text.isalpha()]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes={\n",
    "    'negative':0,\n",
    "    'neutral':1,\n",
    "    'positive':2\n",
    "}\n",
    "\n",
    "TEXT = Field(include_lengths=True, batch_first=True, \n",
    "             tokenize=tokenizer,\n",
    "             eos_token='<eos>',\n",
    "             lower=True,\n",
    "             stop_words=nltk.corpus.stopwords.words('english'))\n",
    "LABEL = LabelField(dtype=tt.int64, use_vocab=True, preprocessing=lambda x: classes[x])\n",
    "\n",
    "dataset = TabularDataset('Tweets.csv', format='csv', \n",
    "                         fields=[(None, None),('label', LABEL), (None, None),(None, None),('text', TEXT)], \n",
    "                         skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2748"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEXT.build_vocab(dataset, min_freq=10, vectors=\"glove.6B.100d\")\n",
    "TEXT.build_vocab(dataset, min_freq=5)\n",
    "len(TEXT.vocab.itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<eos>',\n",
       " 'flight',\n",
       " 'get',\n",
       " 'thanks',\n",
       " 'cancelled',\n",
       " 'service',\n",
       " 'help',\n",
       " 'time']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL.build_vocab(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = dataset.split(0.7, stratified=True)\n",
    "train, valid = train.split(0.7, stratified=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([4498, 1518, 1158], dtype=int64))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in train.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([1927,  651,  496], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in valid.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([2753,  930,  709], dtype=int64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique([x.label for x in test.examples], return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Convolutional NN for text classification\n",
    "\n",
    "Formal definition of convolution of functions $f$ and $g$\n",
    "$$ (f∗g)(t)= \\int_0^{\\infty} f(\\tau)g(t−\\tau) d{\\tau} $$\n",
    "\n",
    "![img](http://www.stokastik.in/wp-content/uploads/2016/09/convolution_ilustration.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, kernels):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        \n",
    "        self.convs = nn.ModuleList([nn.Conv1d(embed_size, hidden_size, k, padding=5) for k in kernels])\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size * len(kernels), 3)\n",
    "        \n",
    "    def forward(self, x, x_lengths):\n",
    "        \n",
    "        x = self.embedding(x)\n",
    "        x = x.transpose(1,2)\n",
    "        \n",
    "        concatenated = []\n",
    "        for conv in self.convs:\n",
    "            z = conv(x)\n",
    "            z = F.avg_pool1d(z, kernel_size=z.size(2))\n",
    "            z = z.squeeze(2)\n",
    "            concatenated.append(z)\n",
    "            \n",
    "        x = tt.cat(concatenated, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt.cuda.empty_cache()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "model = MyModel(len(TEXT.vocab.itos),\n",
    "                embed_size=100,\n",
    "                hidden_size=128,\n",
    "                kernels=[2,3,4,5]\n",
    "               )\n",
    "\n",
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_sizes=(batch_size, batch_size, batch_size),\n",
    "    shuffle=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "#     sort_within_batch=True,\n",
    ")\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=5, verbose=True, cooldown=5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BucketIterator' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-29b0427e0fe8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BucketIterator' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "size = train_iterator.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 82.4154\n",
      "Epoch [2/1000], Loss: 82.3120\n",
      "Epoch [3/1000], Loss: 74.9462\n",
      "Epoch [4/1000], Loss: 84.9559\n"
     ]
    }
   ],
   "source": [
    "# train ...\n",
    "#model = MyModel(vocab_size, embed_size, hidden_size, kernels)\n",
    "n_epochs = 1000\n",
    "min_loss = 0\n",
    "early = 0\n",
    "for epoch in range(n_epochs):  \n",
    "    loss = 0\n",
    "    for batch in train_iterator:\n",
    "        optimizer.zero_grad()\n",
    "        pred = model.forward(batch.text[0], None)\n",
    "        criterion(pred, batch.label).backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "    for batch in valid_iterator:\n",
    "        pred_valid = model.forward(batch.text[0], None)\n",
    "        loss += criterion(pred_valid, batch.label)\n",
    "    \n",
    "    print('Epoch [%d/%d], Loss: %.4f'\n",
    "          %(epoch+1, n_epochs, loss))\n",
    "        \n",
    "    # early stopping\n",
    "    if loss < min_loss:\n",
    "        min_loss = loss\n",
    "        early = 0\n",
    "    else:\n",
    "        early += 1\n",
    "    if early > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
