{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4: Named entity recognition\n",
    "\n",
    "Построить модель для обнаружения и классификации именованных сущностей (named entities). На базе корпуса CoNLL 2002.  \n",
    "\n",
    "Используйте в своем решении ансамбли над решающими деревьями: RandomForest, Gradient Boosting (xgboost, lightgbm, catboost) \n",
    "Tutorials:  \n",
    "1. https://github.com/Microsoft/LightGBM/tree/master/examples/python-guide\n",
    "1. https://github.com/catboost/tutorials \n",
    "\n",
    "\n",
    "Чем больше baseline'ов вы превзойдете, тем выше ваша оценка\n",
    "Метрика качества f1 (f1_macro) (чем выше, тем лучше)\n",
    " \n",
    "baseline 1: 0.0604      random labels  \n",
    "baseline 2: 0.3966      PoS features + logistic regression  \n",
    "baseline 3: 0.8122      word2vec cbow embedding + baseline 2 + svm    \n",
    "\n",
    "! Your results must be reproducible. Если ваша модель - стохастическая, то вы явно должны задавать все seed и random_state в параметрах моделей   \n",
    "\n",
    "bonus, think about:  \n",
    "1. How can you exploit that words belong to some sentence?\n",
    "2. Why we selected f1 score with macro averaging as our classification quality measure? What other metrics are suitable?   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn import model_selection\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "SEED=1337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>1.0</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>1.0</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>1.0</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>1.0</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>1.0</td>\n",
       "      <td>through</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>VB</td>\n",
       "      <td>protest</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>NNP</td>\n",
       "      <td>IN</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>through</td>\n",
       "      <td>1.0</td>\n",
       "      <td>London</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>VB</td>\n",
       "      <td>protest</td>\n",
       "      <td>TO</td>\n",
       "      <td>NNP</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>London</td>\n",
       "      <td>1.0</td>\n",
       "      <td>to</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NN</td>\n",
       "      <td>war</td>\n",
       "      <td>DT</td>\n",
       "      <td>the</td>\n",
       "      <td>VB</td>\n",
       "      <td>TO</td>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>to</td>\n",
       "      <td>1.0</td>\n",
       "      <td>protest</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>NN</td>\n",
       "      <td>war</td>\n",
       "      <td>DT</td>\n",
       "      <td>VB</td>\n",
       "      <td>TO</td>\n",
       "      <td>to</td>\n",
       "      <td>protest</td>\n",
       "      <td>1.0</td>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  next-next-pos next-next-word next-pos      next-word  pos    prev-pos  \\\n",
       "0           NNS  demonstrators       IN             of  NNS  __START1__   \n",
       "1           VBP           have      NNS  demonstrators   IN         NNS   \n",
       "2           VBN        marched      VBP           have  NNS          IN   \n",
       "3            IN        through      VBN        marched  VBP         NNS   \n",
       "4           NNP         London       IN        through  VBN         VBP   \n",
       "5            TO             to      NNP         London   IN         VBN   \n",
       "6            VB        protest       TO             to  NNP          IN   \n",
       "7            DT            the       VB        protest   TO         NNP   \n",
       "8            NN            war       DT            the   VB          TO   \n",
       "9            IN             in       NN            war   DT          VB   \n",
       "\n",
       "  prev-prev-pos prev-prev-word      prev-word  sentence_idx           word  \\\n",
       "0    __START2__     __START2__     __START1__           1.0      Thousands   \n",
       "1    __START1__     __START1__      Thousands           1.0             of   \n",
       "2           NNS      Thousands             of           1.0  demonstrators   \n",
       "3            IN             of  demonstrators           1.0           have   \n",
       "4           NNS  demonstrators           have           1.0        marched   \n",
       "5           VBP           have        marched           1.0        through   \n",
       "6           VBN        marched        through           1.0         London   \n",
       "7            IN        through         London           1.0             to   \n",
       "8           NNP         London             to           1.0        protest   \n",
       "9            TO             to        protest           1.0            the   \n",
       "\n",
       "     tag  \n",
       "0      O  \n",
       "1      O  \n",
       "2      O  \n",
       "3      O  \n",
       "4      O  \n",
       "5      O  \n",
       "6  B-geo  \n",
       "7      O  \n",
       "8      O  \n",
       "9      O  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ner_short.csv', index_col=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of sentences\n",
    "df.sentence_idx.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "O        0.852828\n",
       "B-geo    0.027604\n",
       "B-gpe    0.020935\n",
       "B-org    0.020247\n",
       "I-per    0.017795\n",
       "B-tim    0.016927\n",
       "B-per    0.015312\n",
       "I-org    0.013937\n",
       "I-geo    0.005383\n",
       "I-tim    0.004247\n",
       "B-art    0.001376\n",
       "I-gpe    0.000837\n",
       "I-art    0.000748\n",
       "B-eve    0.000628\n",
       "I-eve    0.000508\n",
       "B-nat    0.000449\n",
       "I-nat    0.000239\n",
       "Name: tag, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# class distribution\n",
    "df.tag.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence length\n",
    "tdf = df.set_index('sentence_idx')\n",
    "tdf['length'] = df.groupby('sentence_idx').tag.count()\n",
    "df = tdf.reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentence_idx</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>have</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>NNS</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>IN</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>NNP</td>\n",
       "      <td>London</td>\n",
       "      <td>IN</td>\n",
       "      <td>through</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VBP</td>\n",
       "      <td>NNS</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             next-next-pos next-next-word next-pos      next-word  pos  \\\n",
       "sentence_idx                                                             \n",
       "1.0                    NNS  demonstrators       IN             of  NNS   \n",
       "1.0                    VBP           have      NNS  demonstrators   IN   \n",
       "1.0                    VBN        marched      VBP           have  NNS   \n",
       "1.0                     IN        through      VBN        marched  VBP   \n",
       "1.0                    NNP         London       IN        through  VBN   \n",
       "\n",
       "                prev-pos prev-prev-pos prev-prev-word      prev-word  \\\n",
       "sentence_idx                                                           \n",
       "1.0           __START1__    __START2__     __START2__     __START1__   \n",
       "1.0                  NNS    __START1__     __START1__      Thousands   \n",
       "1.0                   IN           NNS      Thousands             of   \n",
       "1.0                  NNS            IN             of  demonstrators   \n",
       "1.0                  VBP           NNS  demonstrators           have   \n",
       "\n",
       "                       word tag  length  \n",
       "sentence_idx                             \n",
       "1.0               Thousands   O      48  \n",
       "1.0                      of   O      48  \n",
       "1.0           demonstrators   O      48  \n",
       "1.0                    have   O      48  \n",
       "1.0                 marched   O      48  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode categorial variables\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['pos'] = le.fit_transform(df.pos)\n",
    "df['next-pos'] = le.fit_transform(df['next-pos'])\n",
    "df['next-next-pos'] = le.fit_transform(df['next-next-pos'])\n",
    "df['prev-pos'] = le.fit_transform(df['prev-pos'])\n",
    "df['prev-prev-pos'] = le.fit_transform(df['prev-prev-pos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_idx</th>\n",
       "      <th>next-next-pos</th>\n",
       "      <th>next-next-word</th>\n",
       "      <th>next-pos</th>\n",
       "      <th>next-word</th>\n",
       "      <th>pos</th>\n",
       "      <th>prev-pos</th>\n",
       "      <th>prev-prev-pos</th>\n",
       "      <th>prev-prev-word</th>\n",
       "      <th>prev-word</th>\n",
       "      <th>word</th>\n",
       "      <th>tag</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>__START2__</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>39</td>\n",
       "      <td>__START1__</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>have</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>marched</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>9</td>\n",
       "      <td>of</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>16</td>\n",
       "      <td>London</td>\n",
       "      <td>9</td>\n",
       "      <td>through</td>\n",
       "      <td>32</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>have</td>\n",
       "      <td>marched</td>\n",
       "      <td>O</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence_idx  next-next-pos next-next-word  next-pos      next-word  pos  \\\n",
       "0           1.0             18  demonstrators         9             of   18   \n",
       "1           1.0             33           have        18  demonstrators    9   \n",
       "2           1.0             32        marched        33           have   18   \n",
       "3           1.0              9        through        32        marched   33   \n",
       "4           1.0             16         London         9        through   32   \n",
       "\n",
       "   prev-pos  prev-prev-pos prev-prev-word      prev-word           word tag  \\\n",
       "0        39             40     __START2__     __START1__      Thousands   O   \n",
       "1        18             39     __START1__      Thousands             of   O   \n",
       "2         9             18      Thousands             of  demonstrators   O   \n",
       "3        18              9             of  demonstrators           have   O   \n",
       "4        33             18  demonstrators           have        marched   O   \n",
       "\n",
       "   length  \n",
       "0      48  \n",
       "1      48  \n",
       "2      48  \n",
       "3      48  \n",
       "4      48  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 50155\n",
      "test 16719\n"
     ]
    }
   ],
   "source": [
    "# splitting\n",
    "y = LabelEncoder().fit_transform(df.tag)\n",
    "\n",
    "df_train, df_test, y_train, y_test = model_selection.train_test_split(df, y, stratify=y, \n",
    "                                                                      test_size=0.25, random_state=SEED, shuffle=True)\n",
    "print('train', df_train.shape[0])\n",
    "print('test', df_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some wrappers to work with word2vec\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from collections import defaultdict\n",
    "\n",
    "   \n",
    "class Word2VecWrapper(TransformerMixin):\n",
    "    def __init__(self, window=5,negative=5, size=100, iter=100, is_cbow=False, random_state=SEED):\n",
    "        self.window_ = window\n",
    "        self.negative_ = negative\n",
    "        self.size_ = size\n",
    "        self.iter_ = iter\n",
    "        self.is_cbow_ = is_cbow\n",
    "        self.w2v = None\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def get_size(self):\n",
    "        return self.size_\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X: list of strings\n",
    "        \"\"\"\n",
    "        sentences_list = [x.split() for x in X]\n",
    "        self.w2v = Word2Vec(sentences_list, \n",
    "                            window=self.window_,\n",
    "                            negative=self.negative_, \n",
    "                            size=self.size_, \n",
    "                            iter=self.iter_,\n",
    "                            sg=not self.is_cbow_, seed=self.random_state)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def has(self, word):\n",
    "        return word in self.w2v\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        X: a list of words\n",
    "        \"\"\"\n",
    "        if self.w2v is None:\n",
    "            raise Exception('model not fitted')\n",
    "        return np.array([self.w2v[w] if w in self.w2v else np.zeros(self.size_) for w in X ])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 34 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# here we exploit that word2vec is an unsupervised learning algorithm\n",
    "# so we can train it on the whole dataset (subject to discussion)\n",
    "\n",
    "sentences_list = [x.strip() for x in ' '.join(df.word).split('.')]\n",
    "\n",
    "w2v_cbow = Word2VecWrapper(window=5, negative=5, size=300, iter=300, is_cbow=True, random_state=SEED)\n",
    "w2v_cbow.fit(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.05887736725599869\n",
      "test 0.060439542712750365\n",
      "Wall time: 335 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 1 \n",
    "# random labels\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', DummyClassifier(random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.46639500282346874\n",
      "test 0.39660981421559566\n",
      "Wall time: 2h 29min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 2 \n",
    "# pos features + one hot encoding + logistic regression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "columns = ['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']\n",
    "\n",
    "model = Pipeline([\n",
    "    ('enc', OneHotEncoder()),\n",
    "    ('est', LogisticRegressionCV(Cs=5, cv=5, n_jobs=-1, scoring='f1_macro', \n",
    "                             penalty='l2', solver='newton-cg', multi_class='multinomial', random_state=SEED)),\n",
    "])\n",
    "\n",
    "model.fit(df_train[columns], y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(df_train[columns]), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(df_test[columns]), average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed: 14.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9568881501474211\n",
      "test 0.8093016932978506\n",
      "Wall time: 17min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# baseline 3\n",
    "# use word2vec cbow embedding + baseline 2 + svm\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.svm import LinearSVC\n",
    "import scipy.sparse as sp\n",
    "\n",
    "embeding = w2v_cbow\n",
    "encoder_pos = OneHotEncoder()\n",
    "X_train = sp.hstack([\n",
    "    embeding.transform(df_train.word),\n",
    "    embeding.transform(df_train['next-word']),\n",
    "    embeding.transform(df_train['next-next-word']),\n",
    "    embeding.transform(df_train['prev-word']),\n",
    "    embeding.transform(df_train['prev-prev-word']),\n",
    "    encoder_pos.fit_transform(df_train[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "X_test = sp.hstack([\n",
    "    embeding.transform(df_test.word),\n",
    "    embeding.transform(df_test['next-word']),\n",
    "    embeding.transform(df_test['next-next-word']),\n",
    "    embeding.transform(df_test['prev-word']),\n",
    "    embeding.transform(df_test['prev-prev-word']),\n",
    "    encoder_pos.transform(df_test[['pos','next-pos','next-next-pos','prev-pos','prev-prev-pos']])\n",
    "])\n",
    "\n",
    "model = model_selection.GridSearchCV(LinearSVC(penalty='l2', multi_class='ovr', random_state=SEED), \n",
    "                                    {'C': np.logspace(-4, 0, 5)}, \n",
    "                                    cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print('train', metrics.f1_score(y_train, model.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, model.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем random forest classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возьмём сразу те данные, которые с word2vec cbow embeddings, потому что как видно на сравнении baseline 2 и baseline 3 - это повышает f1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load scikit's random forest classifier library\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_jobs=-1, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n",
       "            oob_score=False, random_state=1337, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.9850458602901792\n",
      "test 0.821452120112657\n",
      "Wall time: 6.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('train', metrics.f1_score(y_train, clf.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, clf.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Ура, бейзлайн побит*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Теперь попробуем градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "# я в итоге стала использовать метод fit, а не train, поэтому это не пригодилось"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of classes for parameters in lgb\n",
    "len(df.tag.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'boosting_type': 'gbdt',\n",
    "          'objective': 'multiclass',\n",
    "          'num_class': 17,\n",
    "          'learning_rate': 0.03,\n",
    "          'num_leaves': 40,\n",
    "          'feature_fraction': 0.5,\n",
    "          'bagging_fraction': 0.3,\n",
    "          'reg_alpha': 0.15,\n",
    "          'reg_lambda': 0.15,\n",
    "          'seed': SEED}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = LGBMClassifier(boosting_type='gbdt',\n",
    "                     objective='multiclass',\n",
    "                     num_class=17,\n",
    "                     learning_rate=0.03,\n",
    "                     num_leaves=40,\n",
    "                     seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_logloss: 0.651774\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_logloss: 0.600979\n",
      "[3]\tvalid_0's multi_logloss: 0.574088\n",
      "[4]\tvalid_0's multi_logloss: 0.535768\n",
      "[5]\tvalid_0's multi_logloss: 0.510486\n",
      "[6]\tvalid_0's multi_logloss: 0.490365\n",
      "[7]\tvalid_0's multi_logloss: 0.479085\n",
      "[8]\tvalid_0's multi_logloss: 0.452253\n",
      "[9]\tvalid_0's multi_logloss: 0.436436\n",
      "[10]\tvalid_0's multi_logloss: 0.428979\n",
      "[11]\tvalid_0's multi_logloss: 0.410815\n",
      "[12]\tvalid_0's multi_logloss: 0.39742\n",
      "[13]\tvalid_0's multi_logloss: 0.385544\n",
      "[14]\tvalid_0's multi_logloss: 0.374343\n",
      "[15]\tvalid_0's multi_logloss: 0.363954\n",
      "[16]\tvalid_0's multi_logloss: 0.354038\n",
      "[17]\tvalid_0's multi_logloss: 0.344688\n",
      "[18]\tvalid_0's multi_logloss: 0.335916\n",
      "[19]\tvalid_0's multi_logloss: 0.327443\n",
      "[20]\tvalid_0's multi_logloss: 0.31944\n",
      "[21]\tvalid_0's multi_logloss: 0.311866\n",
      "[22]\tvalid_0's multi_logloss: 0.304594\n",
      "[23]\tvalid_0's multi_logloss: 0.297608\n",
      "[24]\tvalid_0's multi_logloss: 0.290889\n",
      "[25]\tvalid_0's multi_logloss: 0.284473\n",
      "[26]\tvalid_0's multi_logloss: 0.278388\n",
      "[27]\tvalid_0's multi_logloss: 0.272519\n",
      "[28]\tvalid_0's multi_logloss: 0.266861\n",
      "[29]\tvalid_0's multi_logloss: 0.261417\n",
      "[30]\tvalid_0's multi_logloss: 0.256205\n",
      "[31]\tvalid_0's multi_logloss: 0.251181\n",
      "[32]\tvalid_0's multi_logloss: 0.246281\n",
      "[33]\tvalid_0's multi_logloss: 0.241587\n",
      "[34]\tvalid_0's multi_logloss: 0.237079\n",
      "[35]\tvalid_0's multi_logloss: 0.232695\n",
      "[36]\tvalid_0's multi_logloss: 0.228416\n",
      "[37]\tvalid_0's multi_logloss: 0.224255\n",
      "[38]\tvalid_0's multi_logloss: 0.220325\n",
      "[39]\tvalid_0's multi_logloss: 0.216524\n",
      "[40]\tvalid_0's multi_logloss: 0.212783\n",
      "[41]\tvalid_0's multi_logloss: 0.209185\n",
      "[42]\tvalid_0's multi_logloss: 0.205713\n",
      "[43]\tvalid_0's multi_logloss: 0.202327\n",
      "[44]\tvalid_0's multi_logloss: 0.199041\n",
      "[45]\tvalid_0's multi_logloss: 0.195816\n",
      "[46]\tvalid_0's multi_logloss: 0.192771\n",
      "[47]\tvalid_0's multi_logloss: 0.189739\n",
      "[48]\tvalid_0's multi_logloss: 0.186763\n",
      "[49]\tvalid_0's multi_logloss: 0.183908\n",
      "[50]\tvalid_0's multi_logloss: 0.181148\n",
      "[51]\tvalid_0's multi_logloss: 0.178485\n",
      "[52]\tvalid_0's multi_logloss: 0.175889\n",
      "[53]\tvalid_0's multi_logloss: 0.173421\n",
      "[54]\tvalid_0's multi_logloss: 0.170994\n",
      "[55]\tvalid_0's multi_logloss: 0.168632\n",
      "[56]\tvalid_0's multi_logloss: 0.166284\n",
      "[57]\tvalid_0's multi_logloss: 0.164002\n",
      "[58]\tvalid_0's multi_logloss: 0.161783\n",
      "[59]\tvalid_0's multi_logloss: 0.159633\n",
      "[60]\tvalid_0's multi_logloss: 0.157586\n",
      "[61]\tvalid_0's multi_logloss: 0.155527\n",
      "[62]\tvalid_0's multi_logloss: 0.15351\n",
      "[63]\tvalid_0's multi_logloss: 0.151556\n",
      "[64]\tvalid_0's multi_logloss: 0.149684\n",
      "[65]\tvalid_0's multi_logloss: 0.147859\n",
      "[66]\tvalid_0's multi_logloss: 0.146015\n",
      "[67]\tvalid_0's multi_logloss: 0.144259\n",
      "[68]\tvalid_0's multi_logloss: 0.142493\n",
      "[69]\tvalid_0's multi_logloss: 0.140727\n",
      "[70]\tvalid_0's multi_logloss: 0.138997\n",
      "[71]\tvalid_0's multi_logloss: 0.137342\n",
      "[72]\tvalid_0's multi_logloss: 0.13571\n",
      "[73]\tvalid_0's multi_logloss: 0.134128\n",
      "[74]\tvalid_0's multi_logloss: 0.132573\n",
      "[75]\tvalid_0's multi_logloss: 0.131085\n",
      "[76]\tvalid_0's multi_logloss: 0.129629\n",
      "[77]\tvalid_0's multi_logloss: 0.128152\n",
      "[78]\tvalid_0's multi_logloss: 0.126738\n",
      "[79]\tvalid_0's multi_logloss: 0.125381\n",
      "[80]\tvalid_0's multi_logloss: 0.124017\n",
      "[81]\tvalid_0's multi_logloss: 0.122757\n",
      "[82]\tvalid_0's multi_logloss: 0.121455\n",
      "[83]\tvalid_0's multi_logloss: 0.120244\n",
      "[84]\tvalid_0's multi_logloss: 0.118996\n",
      "[85]\tvalid_0's multi_logloss: 0.117774\n",
      "[86]\tvalid_0's multi_logloss: 0.116634\n",
      "[87]\tvalid_0's multi_logloss: 0.115514\n",
      "[88]\tvalid_0's multi_logloss: 0.11439\n",
      "[89]\tvalid_0's multi_logloss: 0.113315\n",
      "[90]\tvalid_0's multi_logloss: 0.112262\n",
      "[91]\tvalid_0's multi_logloss: 0.111201\n",
      "[92]\tvalid_0's multi_logloss: 0.110222\n",
      "[93]\tvalid_0's multi_logloss: 0.109218\n",
      "[94]\tvalid_0's multi_logloss: 0.108278\n",
      "[95]\tvalid_0's multi_logloss: 0.107314\n",
      "[96]\tvalid_0's multi_logloss: 0.106424\n",
      "[97]\tvalid_0's multi_logloss: 0.105516\n",
      "[98]\tvalid_0's multi_logloss: 0.104642\n",
      "[99]\tvalid_0's multi_logloss: 0.103781\n",
      "[100]\tvalid_0's multi_logloss: 0.102907\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.102907\n",
      "Wall time: 23min 29s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0.03, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_class=17, num_leaves=40,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, seed=1337, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "gbm.fit(X_train, y_train,\n",
    "        eval_set=[(X_test, y_test)],\n",
    "        early_stopping_rounds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "train 0.9800463804961659\n",
      "test 0.8268352127815337\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Starting predicting...')\n",
    "# eval\n",
    "print('train', metrics.f1_score(y_train, gbm.predict(X_train, num_iteration=100), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, gbm.predict(X_test, num_iteration=100), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.827 это конечно немного лучше, чем 0.822. Но мне не нравится, что в fit использовались данные теста для валидации, поэтому попробуем обойтись без этого и добавить больше параметров. Например, bagging и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2 = LGBMClassifier(boosting_type='gbdt',\n",
    "                      objective='multiclass',\n",
    "                      num_class=17,\n",
    "                      learning_rate=0.03,\n",
    "                      num_leaves=45,\n",
    "                      feature_fraction=0.5,\n",
    "                      bagging_fraction=0.3,\n",
    "                      seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 23min 43s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.3, boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=1.0, feature_fraction=0.5,\n",
       "        importance_type='split', learning_rate=0.03, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_class=17, num_leaves=45,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, seed=1337, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "gbm2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "train 0.9810162197763342\n",
      "test 0.8421804050931931\n",
      "Wall time: 39.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Starting predicting...')\n",
    "# eval\n",
    "print('train', metrics.f1_score(y_train, gbm2.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, gbm2.predict(X_test), average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ура, f1 score 0.84. Это выше и бейзлайна и предыдущих двух методов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поиграв еще немного с парметром количество листьев, я получила модель еще получше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm3 = LGBMClassifier(boosting_type='gbdt',\n",
    "                      objective='multiclass',\n",
    "                      num_class=17,\n",
    "                      learning_rate=0.03,\n",
    "                      num_leaves=60,\n",
    "                      feature_fraction=0.5,\n",
    "                      bagging_fraction=0.3,\n",
    "                      seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 24s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(bagging_fraction=0.3, boosting_type='gbdt', class_weight=None,\n",
       "        colsample_bytree=1.0, feature_fraction=0.5,\n",
       "        importance_type='split', learning_rate=0.03, max_depth=-1,\n",
       "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "        n_estimators=100, n_jobs=-1, num_class=17, num_leaves=60,\n",
       "        objective='multiclass', random_state=None, reg_alpha=0.0,\n",
       "        reg_lambda=0.0, seed=1337, silent=True, subsample=1.0,\n",
       "        subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# train\n",
    "gbm3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting predicting...\n",
      "train 0.986631846426279\n",
      "test 0.8534014454489132\n",
      "Wall time: 20.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print('Starting predicting...')\n",
    "# eval\n",
    "print('train', metrics.f1_score(y_train, gbm3.predict(X_train), average='macro'))\n",
    "print('test', metrics.f1_score(y_test, gbm3.predict(X_test), average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
